{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5567\n",
      "5567\n",
      "1856\n",
      "1856\n",
      "7422\n",
      "[[4.970e+02 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [3.080e+02 0.000e+00 1.200e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.169e+03 1.400e+01 7.316e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [9.240e+02 7.000e+00 3.248e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [4.550e+03 7.000e+00 2.644e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [3.850e+02 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]]\n",
      "[0. 1. 1. ... 0. 1. 1.]\n",
      "[[6.300e+01 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [9.030e+02 0.000e+00 8.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [6.720e+02 7.000e+00 6.000e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [7.154e+03 7.000e+00 1.288e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.120e+03 7.000e+00 5.136e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [6.580e+02 7.000e+00 2.156e+03 ... 0.000e+00 0.000e+00 0.000e+00]]\n",
      "[1. 1. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "###Project Kaggle\n",
    "###Daniel Vu\n",
    "###34645787\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'./mltools')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "X_data = np.genfromtxt('./data/X_train.txt',delimiter=',')\n",
    "Y_data = np.genfromtxt('./data/Y_train.txt',delimiter=None)\n",
    "X_test = np.genfromtxt('./data/X_test.txt',delimiter=',')\n",
    "\n",
    "X_train,X_valid,Y_train,Y_valid = ml.splitData(X_data,Y_data,0.75)\n",
    "\n",
    "print(len(X_train))\n",
    "\n",
    "print(len(Y_train))\n",
    "\n",
    "print(len(X_valid))\n",
    "\n",
    "print(len(Y_valid))\n",
    "\n",
    "print(len(X_test))\n",
    "\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "print(Y_train)\n",
    "\n",
    "print(X_valid)\n",
    "\n",
    "print(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC:  1.0\n",
      "Validation AUC:  0.6430924550205157\n",
      "[[9.57933338e-01 4.20666620e-02]\n",
      " [9.94910245e-01 5.08975484e-03]\n",
      " [9.13630983e-01 8.63690170e-02]\n",
      " ...\n",
      " [4.81395279e-01 5.18604721e-01]\n",
      " [6.06876428e-05 9.99939312e-01]\n",
      " [7.81128189e-01 2.18871811e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Boosted Learners: Gradient Boosting\n",
    "\n",
    "gradientBoost = GradientBoostingClassifier(n_estimators=500,max_depth=10,min_samples_split=10,min_samples_leaf=2)\n",
    "fitGradientBoost = gradientBoost.fit(X_train,Y_train)\n",
    "\n",
    "gb = fitGradientBoost.predict_proba(X_test)\n",
    "Yv = fitGradientBoost.predict(X_valid)\n",
    "Yt = fitGradientBoost.predict(X_train)\n",
    "\n",
    "print('Training AUC: ',roc_auc_score(Y_train,Yt))\n",
    "print('Validation AUC: ',roc_auc_score(Y_valid,Yv))\n",
    "print(gb)\n",
    "\n",
    "\n",
    "np.savetxt('submission_gb.csv', np.vstack( (np.arange(len(gb)), gb[:,1]) ).T,'%d, %.2f', header = 'ID,Predicted', comments = '', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC:  1.0\n",
      "Validation AUC:  0.6247311340651832\n",
      "[[0.9099473  0.0900527 ]\n",
      " [0.98730583 0.01269417]\n",
      " [0.55438827 0.44561173]\n",
      " ...\n",
      " [0.38629578 0.61370422]\n",
      " [0.02929474 0.97070526]\n",
      " [0.88401708 0.11598292]]\n"
     ]
    }
   ],
   "source": [
    "#Boosted Learners: Ada Boost\n",
    "\n",
    "adaBoost = AdaBoostClassifier(n_estimators=500,base_estimator = DecisionTreeClassifier(max_depth=10,min_samples_split=10))\n",
    "fitAdaBoost = adaBoost.fit(X_train,Y_train)\n",
    "\n",
    "ab = fitAdaBoost.predict_proba(X_test)\n",
    "Yv = fitAdaBoost.predict(X_valid)\n",
    "Yt = fitAdaBoost.predict(X_train)\n",
    "\n",
    "print('Training AUC: ',roc_auc_score(Y_train,Yt))\n",
    "print('Validation AUC: ',roc_auc_score(Y_valid,Yv))\n",
    "print(ab)\n",
    "\n",
    "\n",
    "np.savetxt('submission_ab.csv', np.vstack( (np.arange(len(ab)), ab[:,1]) ).T,'%d, %.2f', header = 'ID,Predicted', comments = '', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC:  0.9996427295462665\n",
      "Validation AUC:  0.6425387451644803\n",
      "[[0.67397242 0.32602758]\n",
      " [0.78823333 0.21176667]\n",
      " [0.48694103 0.51305897]\n",
      " ...\n",
      " [0.53913187 0.46086813]\n",
      " [0.18390351 0.81609649]\n",
      " [0.50136429 0.49863571]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forests\n",
    "\n",
    "randomForest = RandomForestClassifier(n_estimators = 500,max_depth = 25,min_samples_leaf = 2, oob_score = True)\n",
    "\n",
    "randomForest.fit(X_train,Y_train)\n",
    "\n",
    "rf = randomForest.predict_proba(X_test)\n",
    "\n",
    "Yv = randomForest.predict(X_valid)\n",
    "Yt = randomForest.predict(X_train)\n",
    "\n",
    "print('Training AUC: ',roc_auc_score(Y_train,Yt))\n",
    "print('Validation AUC: ',roc_auc_score(Y_valid,Yv))\n",
    "print(rf)\n",
    "\n",
    "\n",
    "np.savetxt('submission_rf.csv', np.vstack( (np.arange(len(rf)), rf[:,1]) ).T,'%d, %.2f', header = 'ID,Predicted', comments = '', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC:  1.0\n",
      "Validation AUC:  0.5134255757013755\n",
      "[[0.5        0.5       ]\n",
      " [0.5        0.5       ]\n",
      " [0.5        0.5       ]\n",
      " ...\n",
      " [0.44050738 0.55949262]\n",
      " [0.5        0.5       ]\n",
      " [0.5        0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "#Kernel Method: Support Vector Machines\n",
    "\n",
    "supportVM = svm.SVC(C = 100000000, gamma = 0.0000000001 , probability = True)\n",
    "\n",
    "supportVM.fit(X_train,Y_train)\n",
    "\n",
    "s = supportVM.predict_proba(X_test)\n",
    "Yv = supportVM.predict(X_valid)\n",
    "Yt = supportVM.predict(X_train)\n",
    "\n",
    "print('Training AUC: ',roc_auc_score(Y_train,Yt))\n",
    "print('Validation AUC: ',roc_auc_score(Y_valid,Yv))\n",
    "print(s)\n",
    "\n",
    "\n",
    "np.savetxt('submission_s.csv', np.vstack( (np.arange(len(s)), s[:,1]) ).T,'%d, %.2f', header = 'ID,Predicted', comments = '', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC:  0.5419478493557773\n",
      "Validation AUC:  0.50872107548698\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielvu/miniconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Neural Networks\n",
    "\n",
    "neuralNetwork = MLPClassifier(solver = 'adam',random_state =0)\n",
    "neuralNetwork.fit(X_train,Y_train)\n",
    "\n",
    "nn = neuralNetwork.predict_proba(X_test)\n",
    "Yv = neuralNetwork.predict(X_valid)\n",
    "Yt = neuralNetwork.predict(X_train)\n",
    "\n",
    "print('Training AUC: ',roc_auc_score(Y_train,Yt))\n",
    "print('Validation AUC: ',roc_auc_score(Y_valid,Yv))\n",
    "print(nn)\n",
    "\n",
    "\n",
    "np.savetxt('submission_nn_adam.csv', np.vstack( (np.arange(len(nn)), nn[:,1]) ).T,'%d, %.2f', header = 'ID,Predicted', comments = '', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete of 5 Ensembles:\n",
    "completeEnsemble = []\n",
    "\n",
    "completeEnsemble = (gb + ab + rf)/3\n",
    "\n",
    "np.savetxt('submission_vudh1_2.csv', np.vstack( (np.arange(len(completeEnsemble)), completeEnsemble[:,1]) ).T,'%d, %.2f', header = 'ID,Predicted', comments = '', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
